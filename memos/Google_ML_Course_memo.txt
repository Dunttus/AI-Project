________________________________________________________________________________________________________________________________

Google Machine Learning Crash Course key-points memo
________________________________________________________________________________________________________________________________
** Introduction to ML (5min) **
You can make programs that you have no idea how to code by yourself like face recognition.
You can save time by not making 10s of thousands of lines of code of how to recognize speech

COMPARED TO SOFTWARE ENGINEERING
Coding by hand: Logically and mathematically
Machine learning: Focus shifts from mathematical science to natural science
________________________________________________________________________________________________________________________________
** Framing (15min) & Descending into ML (20min) **
LABELS, FEATURE AND MODEL
Task of is email message spam or not spam?
E-mail label = Spam/Not Spam			--> Output target
E-mail feature = "From to user"			--> Data that helps ML decide
E-mail model = "from to user" + "Header"	--> prediction output

MSE = Mean Squared Error = Calculated Error rate for machine learning 
________________________________________________________________________________________________________________________________
** Reducing loss (60min) **
Loss vs. Weight meter goes over data curve and takes step back.

A Machine Learning model is trained by starting with an initial guess for the weights and bias and iteratively adjusting 
those guesses until learning the weights and bias with the lowest possible loss.

Gradient decent in TensorFlow handles all the gradient computations automatically for you, so you don't actually have to 
understand the calculus provided in Googles ml crash course.

Play with reduce loss:
http://playground.tensorflow.org/

TensorFlow 2 QuickStart for beginners:
https://www.tensorflow.org/tutorials/quickstart/beginner
________________________________________________________________________________________________________________________________
** First Steps with TensorFlow (60min) **
tf.estimator = high lvl API that contain functions like model, loss, optimizer and other metrics. So, estimator lowers 
numbers of lines of code end user writes.
High lvl APIs have less flexibility but easier to get working. If better flexibility is needed move one level lower.
Estimator process of training dataset choose model: LinearClassifier --> train dataset: classifier.train(input) --> 
predict from testdata: classifier.predict(input).

TensorFlow uses graph execution by default. Graph mode execute all code in 1 go so it's really hard to debug code with 
out cell execution. So. you have to use cell execution to link code together and execute it in small portions.
________________________________________________________________________________________________________________________________
** Generalization (15min) **
Dataset has to be simple overfitting model can cause mis categorization and model may fails to make correct predictions 
on new data.
Linear model may have error rate but it's better than having 100% model that can't handle new data coming to the model 
and miscategorized never before seen examples of data.
Separating dataset in 2 subsets: Training set and test set with unseen data helps performance the dataset.
________________________________________________________________________________________________________________________________
** Training and test sets (25min) **
Train - train machine learning model with this data.
Test - test trained machine learning model with this data.
If you only have one train data, you should slit your data set into train and test data. Test dataset should me around 10-15%
and from random parts of the dataset.
You never want to train with your test data, or your model will be unrealistic and may even give 100% results.
________________________________________________________________________________________________________________________________
** Validation Set (40min) **
Using same dataset to validate data may cause overfitting of the model.
Validation set - validates machine learning model before test dataset can help with overfitting models.
Using validation set to evaluate training set results, help with overfitting because machine learning model is learning 
all data you feed it. 
________________________________________________________________________________________________________________________________
** Representation (65min) **
Taking features from raw data is called feature engineering, and that's what 75% of the time machine learning people end up doing.
If feature only occurs a non-zero value extremely rarely or once, it should be filtered out in preprocessing of dataset.
Feature values should not change in new datasets to completely different values also feature value should not have 
extreme outliers.
Good habits: Visualize data, debug data and monitor data.

Good feature values should appear more than 5 times in training dataset. So, the model learns how value relates to label value.
Avoid rare or unique feature values like: unique_phone_sm_id: SM-123-aSd-123. Good features are easily recognizable and 
obvious meaning like: phone_model: galaxy_a8. Unique features bad because model can't learn anything from its unique label. 
Bad for datasets: Forgotten values (forgotten values), duplicate examples (same log twice), bad labels (wrong info) and bad 
feature values (extra digits).

Discrete feature - value that has only finite set of possible outcome values (usually categorical value).
Feature engineering - determining which features are useful in training dataset model.
Magic values - if dataset has floating point value of 0-100, you can't use -1 as label value.
Bucketing - putting same data in same bucket like ages 1-15 in same bin and ages 16-30 in second bin.
NaN trap - one of the numbers becomes NaN in training phase and eventually turn other numbers NaN.
________________________________________________________________________________________________________________________________
** Feature Crosses (70min) **
Combining linear and cross learning can be extremely powerful for modeling.

Linear model - you can draw straight line in middle and separate data types in dataset, if single line can't do this you need 
feature crosses which combine many data features together.

When creating machine learning feature model think of these questions:
Which features help most?
What is the best performance that you can get?
Does it look like a linear model?
How would you describe the model?

Good model to predict housing prices in certain area could be:
One feature cross: [binned latitude X binned longitude X binned roomsPerPerson]
________________________________________________________________________________________________________________________________
** Regularization: Simplicity (40min) **
________________________________________________________________________________________________________________________________
** Logistic Regression (20min) **
________________________________________________________________________________________________________________________________
** Classification (90min) **
________________________________________________________________________________________________________________________________
** Reqularization: Sparsity (45min) **
________________________________________________________________________________________________________________________________
** Neural Networks (55min) **
________________________________________________________________________________________________________________________________
** Training Neural Nets (40min) **
________________________________________________________________________________________________________________________________
** Multi-Class Neural Nets (50min) **
________________________________________________________________________________________________________________________________
** Embeddings (80min) **
________________________________________________________________________________________________________________________________

SOURCES:
Google Machine Learning Crash Course: https://developers.google.com/machine-learning/crash-course/
License Creative Commons Attribution 4.0: https://creativecommons.org/licenses/by/4.0/
________________________________________________________________________________________________________________________________



